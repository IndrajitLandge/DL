import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Dataset directory (replace this with your actual path)
DATA_DIR = '/path/to/apple_leaf_dataset'  # <-- Update this

# Parameters
IMG_SIZE = (128, 128)
BATCH_SIZE = 32
EPOCHS = 15
LEARNING_RATE = 0.001

# Load dataset (without .map)
def load_dataset():
    train_ds = tf.keras.preprocessing.image_dataset_from_directory(
        DATA_DIR,
        validation_split=0.2,
        subset="training",
        seed=42,
        image_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        label_mode='int'
    )
    val_ds = tf.keras.preprocessing.image_dataset_from_directory(
        DATA_DIR,
        validation_split=0.2,
        subset="validation",
        seed=42,
        image_size=IMG_SIZE,
        batch_size=BATCH_SIZE,
        label_mode='int'
    )

    # Convert to numpy arrays
    def to_numpy(ds):
        images, labels = [], []
        for x, y in ds:
            images.append(x)
            labels.append(y)
        x = tf.concat(images, axis=0).numpy() / 255.0
        y = tf.concat(labels, axis=0).numpy()
        return x, y

    x_train, y_train = to_numpy(train_ds)
    x_val, y_val = to_numpy(val_ds)
    class_names = train_ds.class_names

    return (x_train, y_train), (x_val, y_val), class_names

# CNN Model with Dropout layers
def build_model(num_classes):
    model = tf.keras.Sequential([
        tf.keras.layers.InputLayer(input_shape=(*IMG_SIZE, 3)),
        tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Dropout(0.25),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

# Load data
(x_train, y_train), (x_val, y_val), class_names = load_dataset()

# Build and train model
model = build_model(num_classes=len(class_names))
history = model.fit(x_train, y_train,
                    validation_data=(x_val, y_val),
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE)

# Evaluate model
val_loss, val_accuracy = model.evaluate(x_val, y_val, verbose=0)
print(f"\nValidation Accuracy: {val_accuracy:.4f}")
print(f"Validation Loss: {val_loss:.4f}")

# Plot accuracy and loss
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Accuracy over 15 Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss over 15 Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()
